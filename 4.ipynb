{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/xiong-p/.conda/envs/cu111/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/yanai-lab/xiong-p/.conda/envs/cu111/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yanai-lab/xiong-p/.conda/envs/cu111/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /home/yanai-lab/xiong-p/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:02<00:00, 88.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608 -> n02124075 Egyptian cat\n",
      "0.117 -> n02123159 tiger cat\n",
      "0.094 -> n02123394 Persian cat\n",
      "0.044 -> n02123045 tabby, tabby cat\n",
      "0.014 -> n01622779 great grey owl, great gray owl, Strix nebulosa\n",
      "output n02124075 Egyptian cat.jpg for the top-1 prediction: n02124075 Egyptian cat\n",
      "output n02123159 tiger cat.jpg for the top-2 prediction: n02123159 tiger cat\n",
      "output n02123394 Persian cat.jpg for the top-3 prediction: n02123394 Persian cat\n",
      "output n02123045 tabby, tabby cat.jpg for the top-4 prediction: n02123045 tabby, tabby cat\n",
      "output n01622779 great grey owl, great gray owl, Strix nebulosa.jpg for the top-5 prediction: n01622779 great grey owl, great gray owl, Strix nebulosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2995061/3499547503.py:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(output).data.squeeze()\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from functools import partial\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# load a pretrained model, such a model already has a global pooling at the end\n",
    "# model_id: 1 - SqueezeNet, 2 - ResNet, 3 - DenseNet\n",
    "def load_model(model_id):\n",
    "    if model_id == 1:\n",
    "        model = models.squeezenet1_1(pretrained = True)\n",
    "        final_conv_layer = 'classifier.1'\n",
    "    elif model_id == 2:\n",
    "        model = models.resnet101(pretrained = True)\n",
    "        final_conv_layer = 'layer4'\n",
    "    elif model_id == 3:\n",
    "        model = models.densenet161(pretrained = True)\n",
    "        final_conv_layer = 'features'\n",
    "    else:\n",
    "        sys.exit('No such model!')\n",
    "\n",
    "    return model, final_conv_layer\n",
    "\n",
    "# a hook to a given layer\n",
    "def hook(module, input, output, feature_blob):\n",
    "    feature_blob.append(output.data.numpy())\n",
    "\n",
    "# load and preprocess an image\n",
    "def load_image(filename = './cat.jpg'):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    image = preprocess(image)\n",
    "\n",
    "    return Variable(image.unsqueeze(0))\n",
    "\n",
    "# read in labels, original file url: https://s3.amazonaws.com/outcome-blog/imagenet/labels.json\n",
    "def get_labels(filename = '.1000.txt'):\n",
    "    content=open(filename).read().split('\\n')\n",
    "    # labels = {int(k) : v for (k, v) in content}\n",
    "    return content\n",
    "\n",
    "# compute class activation map\n",
    "def compute_cam(activation, softmax_weight, class_ids):\n",
    "    b, c, h, w = activation.shape\n",
    "    cams = []\n",
    "    for idx in class_ids:\n",
    "        activation = activation.reshape(c, h * w)\n",
    "        cam = softmax_weight[idx].dot(activation)\n",
    "        cam = cam.reshape(h, w)\n",
    "        # normalize to [0, 1]\n",
    "        cam =  (cam - cam.min()) / (cam.max() - cam.min())\n",
    "        # conver to [0, 255]\n",
    "        cam = np.uint8(255 * cam)\n",
    "        # reshape to (224, 224)\n",
    "        cams.append(cv2.resize(cam, (224, 224)))\n",
    "\n",
    "    return cams\n",
    "\n",
    "\n",
    "# load a pretrained model\n",
    "model, final_conv_layer = load_model(2)    # model_id: 1 - SqueezeNet, 2 - ResNet, 3 - DenseNet\n",
    "model.eval()\n",
    "\n",
    "# add a hook to a given layer\n",
    "feature_blob = []\n",
    "model._modules.get(final_conv_layer).register_forward_hook(partial(hook, feature_blob = feature_blob))\n",
    "\n",
    "# get the softmax (last fc layer) weight\n",
    "params = list(model.parameters())\n",
    "softmax_weight = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "input = load_image('./cat.jpg')\n",
    "\n",
    "output = model(input)   # scores\n",
    "\n",
    "labels = get_labels('./1000.txt')\n",
    "\n",
    "probs = F.softmax(output).data.squeeze()\n",
    "probs, idx = probs.sort(0, descending = True)\n",
    "\n",
    "# output the top-5 prediction\n",
    "for i in range(5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], labels[idx[i]]))\n",
    "\n",
    "# generate class activation map for the top-5 prediction\n",
    "cams = compute_cam(feature_blob[0], softmax_weight, idx[0: 5])\n",
    "\n",
    "for i in range(len(cams)):\n",
    "    # render cam and original image\n",
    "    filename = labels[idx[i]] + '.jpg'\n",
    "    print('output %s for the top-%s prediction: %s' % (filename, (i + 1), labels[idx[i]]))\n",
    "\n",
    "    img = cv2.imread('./cat.jpg')\n",
    "    h, w, _ = img.shape\n",
    "    heatmap = cv2.applyColorMap(cv2.resize(cams[i], (w, h)), cv2.COLORMAP_JET)\n",
    "    result = heatmap * 0.3 + img * 0.5\n",
    "    # plt.imshow(result,cmap='hot')\n",
    "    cv2.imwrite(filename, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1534bd38aaa559217507cba555970b72c3ef25af158b2c243bb4986fc4ab776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
